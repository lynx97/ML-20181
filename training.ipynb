{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = [14, 6]\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from biosppy.signals import ecg\n",
    "#\n",
    "from hrv.classical import time_domain\n",
    "from hrv.classical import frequency_domain\n",
    "from hrv.classical import non_linear\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(833, 10801)\n",
      "(1253, 10801)\n",
      "(902, 10801)\n",
      "(935, 10801)\n",
      "(1105, 10801)\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load(\"1.npy\")\n",
    "data2 = np.load(\"2.npy\")\n",
    "data3 = np.load(\"3.npy\")\n",
    "data4 = np.load(\"4.npy\")\n",
    "data5 = np.load(\"5.npy\")\n",
    "print(data1.shape)\n",
    "print(data2.shape)\n",
    "print(data3.shape)\n",
    "print(data4.shape)\n",
    "print(data5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrvAnalysis(NN):\n",
    "    diffNN = np.absolute(np.diff(NN))\n",
    "    L = len(NN)    \n",
    "    ANN = np.mean(NN)\n",
    "    SDNN = np.std(NN)\n",
    "    SDSD = np.std(diffNN)    \n",
    "    #NN50 = len(np.where(np.diff(NN) > 0.05)[0])    \n",
    "    NN50 = diffNN[diffNN > 0.05].size\n",
    "    pNN50 = NN50/(L - 1)    \n",
    "    rMSSD = np.sqrt(1/(L-1) * sum(diffNN ** 2))        \n",
    "    rangeNum = np.ptp(NN)\n",
    "    \n",
    "    #non linear: pointcare & entropy\n",
    "    #pointcare\n",
    "    sd1, sd2 = poincare(NN)\n",
    "    #entropy\n",
    "    prob_NN = NN / NN.sum()\n",
    "    shannon = -np.sum(prob_NN*np.log2(prob_NN))\n",
    "    \n",
    "    \n",
    "    timeDomainFeats = {'ANN': ANN, 'SDNN': SDNN,\n",
    "                       'SDSD': SDSD,\n",
    "                       'pNN50': pNN50, 'rMSSD':rMSSD, 'sd1': sd1, 'sd2': sd2, 'shannon': shannon}\n",
    "                       \n",
    "    return timeDomainFeats\n",
    "\n",
    "def frequencyDomain(NN):\n",
    "    results = frequency_domain(\n",
    "        rri=NN,\n",
    "        fs=4.0,\n",
    "        method='welch',\n",
    "        interp_method='cubic',\n",
    "        detrend='linear'\n",
    "    )\n",
    "    return results['lf_hf']\n",
    "\n",
    "def poincare(rri):\n",
    "    diff_rri = np.absolute(np.diff(rri))\n",
    "    sd1 = np.sqrt(np.std(diff_rri, ddof=1) ** 2 * 0.5)\n",
    "    sd2 = np.sqrt(2 * np.std(rri, ddof=1) ** 2 - 0.5 * np.std(diff_rri,\n",
    "                                                              ddof=1) ** 2)\n",
    "    return sd1, sd2\n",
    "\n",
    "def cal_r_peaks(signal, sampling_rate):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    rpeaks, = ecg.hamilton_segmenter(signal=signal,\n",
    "                                     sampling_rate=sampling_rate)\n",
    "    rpeaks, = ecg.correct_rpeaks(signal=signal,\n",
    "                                 rpeaks=rpeaks,\n",
    "                                 sampling_rate=sampling_rate,\n",
    "                                 tol=0.05)\n",
    "    templates, rpeaks = ecg.extract_heartbeats(signal=signal,\n",
    "                                               rpeaks=rpeaks,\n",
    "                                               sampling_rate=sampling_rate,\n",
    "                                               before=0.2,\n",
    "                                               after=0.4)\n",
    "    return rpeaks\n",
    "\n",
    "def create_features(raw_data, fs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data  = raw_data[:, :-1]\n",
    "    label = raw_data[:, -1]\n",
    "\n",
    "    result = []\n",
    "    for x in data:\n",
    "        rpeaks = cal_r_peaks(x, fs)\n",
    "        tmp = np.diff(rpeaks)\n",
    "        rri = tmp / fs\n",
    "\n",
    "        time = hrvAnalysis(rri)\n",
    "        result.append(list(time.values()))\n",
    "        \n",
    "    result = np.array(result)\n",
    "    return result, label\n",
    "\n",
    "def train(training_data, testing_data, training_label, testing_label, hidden_layer, activation):\n",
    "    \n",
    "    #scaled data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(training_data)\n",
    "    scaled_training_features = scaler.transform(training_data)\n",
    "    scaler.fit(testing_data)\n",
    "    scaled_testing_features = scaler.transform(testing_data)\n",
    "    \n",
    "    #model\n",
    "    model = MLPClassifier(solver='lbfgs', alpha=5e-3, activation = activation, hidden_layer_sizes=(hidden_layer), learning_rate_init=0.001, max_iter=500)\n",
    "    model.fit(X=scaled_training_features, y=training_label)\n",
    "    prediction = model.predict(scaled_testing_features)\n",
    "    accuracy = accuracy_score(prediction, testing_label)\n",
    "    loss = model.loss_\n",
    "    iteration = model.n_iter_\n",
    "    return accuracy, loss, iteration\n",
    "\n",
    "def kfold(data1, data2, data3, data4, data5, label1, label2, label3, label4, label5, hidden_layer, activation):\n",
    "    #fold 1\n",
    "    training1 = np.concatenate((data2, data3, data4, data5), 0)\n",
    "    training_label1 = np.concatenate((label2, label3, label4, label5), 0)\n",
    "    accuracy1, loss1, iteration1 = train(training1, data1, training_label1, label1, hidden_layer, activation)\n",
    "    #print(\"accuracy:\", accuracy1, \"loss\", loss1, \"iteration\", iteration1)\n",
    "    #end\n",
    "\n",
    "    #fold 2\n",
    "    training2 = np.concatenate((data1, data3, data4, data5), 0)\n",
    "    training_label2 = np.concatenate((label1, label3, label4, label5), 0)\n",
    "    accuracy2, loss2, iteration2 = train(training2, data2, training_label2, label2, hidden_layer, activation)\n",
    "    #print(\"accuracy:\", accuracy1, \"loss\", loss1, \"iteration\", iteration1)\n",
    "    #end\n",
    "\n",
    "    #fold 3\n",
    "    training3 = np.concatenate((data2, data1, data4, data5), 0)\n",
    "    training_label3 = np.concatenate((label2, label1, label4, label5), 0)\n",
    "    accuracy3, loss3, iteration3 = train(training3, data3, training_label3, label3, hidden_layer, activation)\n",
    "    #print(\"accuracy:\", accuracy1, \"loss\", loss1, \"iteration\", iteration1)\n",
    "    #end\n",
    "\n",
    "    #fold 4\n",
    "    training4 = np.concatenate((data2, data3, data1, data5), 0)\n",
    "    training_label4 = np.concatenate((label2, label3, label1, label5), 0)\n",
    "    accuracy4, loss4, iteration4 = train(training4, data4, training_label4, label4, hidden_layer, activation)\n",
    "    #print(\"accuracy:\", accuracy1, \"loss\", loss1, \"iteration\", iteration1)\n",
    "    #end\n",
    "\n",
    "    #fold 5\n",
    "    training5 = np.concatenate((data2, data3, data4, data1), 0)\n",
    "    training_label5 = np.concatenate((label2, label3, label4, label1), 0)\n",
    "    accuracy5, loss5, iteration5 = train(training5, data5, training_label5, label5, hidden_layer, activation)\n",
    "    #print(\"accuracy:\", accuracy1, \"loss\", loss1, \"iteration\", iteration1)\n",
    "    #end\n",
    "    loss_average = (loss1 + loss2 + loss3 + loss4 + loss5)/5\n",
    "    return loss_average\n",
    "\n",
    "def modelSelection(list_activation, list_hidden, data1, data2, data3, data4, data5):\n",
    "    \n",
    "    #create features\n",
    "    training1, label1 = create_features(data1, 360)\n",
    "    training2, label2 = create_features(data2, 360)\n",
    "    training3, label3 = create_features(data3, 360)\n",
    "    training4, label4 = create_features(data4, 360)\n",
    "    training5, label5 = create_features(data5, 360)\n",
    "    \n",
    "    g_loss = 1000\n",
    "    best_hidden = list_hidden[0]\n",
    "    i = 0\n",
    "    for activation in list_activation:\n",
    "        for hidden_layer in list_hidden:\n",
    "            loss = kfold(training1, training2, training3, training4, training5, label1, label2, label3, label4, label5, hidden_layer, activation)\n",
    "            i = i+1\n",
    "            if(loss < g_loss):\n",
    "                print(\"ith: \", i, \"loss: \", loss, \"hidden_layer\", hidden_layer, \"activation: \", activation)\n",
    "                g_loss = loss\n",
    "                best_hidden = hidden_layer\n",
    "    return g_loss, best_hidden, activation\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the potential parameter - hidden layer\n",
    "B = np.linspace(15, 25, 11, dtype=int)\n",
    "C = np.append(B, B.T, axis = 0)\n",
    "D = C.reshape((2, 11))\n",
    "A2 = D.T\n",
    "B = B.reshape((11,1))\n",
    "A3 = np.append(A2, B, axis = 1)\n",
    "A4 = np.append(A3, B, axis = 1)\n",
    "A5 = np.append(A4, B, axis = 1)\n",
    "\n",
    "\n",
    "#init activation\n",
    "list_activation = ['logistic', 'tanh', 'relu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ith:  1 loss:  0.04871504605588685 hidden_layer [15 15] activation:  logistic\n",
      "ith:  2 loss:  0.048240096439974886 hidden_layer [16 16] activation:  logistic\n",
      "ith:  3 loss:  0.045766704834315594 hidden_layer [17 17] activation:  logistic\n",
      "ith:  4 loss:  0.03709638331428359 hidden_layer [18 18] activation:  logistic\n",
      "ith:  7 loss:  0.033246897589144175 hidden_layer [21 21] activation:  logistic\n",
      "ith:  11 loss:  0.029485152623826717 hidden_layer [25 25] activation:  logistic\n",
      "ith:  12 loss:  0.024272125967532414 hidden_layer [15 15] activation:  tanh\n",
      "ith:  13 loss:  0.02031941751647597 hidden_layer [16 16] activation:  tanh\n",
      "ith:  15 loss:  0.019272809534109363 hidden_layer [18 18] activation:  tanh\n",
      "ith:  16 loss:  0.01570302269065001 hidden_layer [19 19] activation:  tanh\n",
      "ith:  18 loss:  0.014671381092650282 hidden_layer [21 21] activation:  tanh\n",
      "ith:  19 loss:  0.013519182818932449 hidden_layer [22 22] activation:  tanh\n",
      "ith:  20 loss:  0.012254955751607673 hidden_layer [23 23] activation:  tanh\n",
      "ith:  21 loss:  0.01030107216643562 hidden_layer [24 24] activation:  tanh\n"
     ]
    }
   ],
   "source": [
    "#model selection\n",
    "g_loss1, best_hidden1, best_activation = modelSelection(list_activation, A2, data1, data2, data3, data4, data5)\n",
    "print(\"g_loss1: \", g_loss1, \" best_hiddent1: \", best_hidden1, \"best_activation:\", best_activation)\n",
    "\n",
    "#g_loss2, best_hidden2 = modelSelection(list_activation, A3, data1, data2, data3, data4, data5)\n",
    "#print(\"g_loss2: \", g_loss2, \" best_hiddent2: \", best_hidden2)\n",
    "\n",
    "#g_loss3, best_hidden3 = modelSelection(list_activation, A4, data1, data2, data3, data4, data5)\n",
    "#print(\"g_loss3: \", g_loss3, \" best_hiddent3: \", best_hidden3)\n",
    "\n",
    "#g_loss4, best_hidden4 = modelSelection(list_activation, A5, data1, data2, data3, data4, data5)  \n",
    "#print(\"g_loss4: \", g_loss4, \" best_hiddent4: \", best_hidden4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ith:  1 loss:  0.04930500560829211 hidden_layer [15 15 15] activation:  logistic\n",
      "ith:  4 loss:  0.04261962184499117 hidden_layer [18 18 18] activation:  logistic\n",
      "ith:  5 loss:  0.039864879706394254 hidden_layer [19 19 19] activation:  logistic\n",
      "ith:  6 loss:  0.03749530158222221 hidden_layer [20 20 20] activation:  logistic\n",
      "ith:  12 loss:  0.01776539880717056 hidden_layer [15 15 15] activation:  tanh\n",
      "ith:  14 loss:  0.01710972832423601 hidden_layer [17 17 17] activation:  tanh\n",
      "ith:  15 loss:  0.01416314431989417 hidden_layer [18 18 18] activation:  tanh\n",
      "ith:  16 loss:  0.011156843394806139 hidden_layer [19 19 19] activation:  tanh\n",
      "ith:  19 loss:  0.00956591233400747 hidden_layer [22 22 22] activation:  tanh\n",
      "ith:  20 loss:  0.00869223563406736 hidden_layer [23 23 23] activation:  tanh\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-380c469ac6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg_loss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hidden2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelSelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"g_loss2: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" best_hiddent2: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hidden2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-493201ce5ede>\u001b[0m in \u001b[0;36mmodelSelection\u001b[0;34m(list_activation, list_hidden, data1, data2, data3, data4, data5)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_activation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhidden_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-493201ce5ede>\u001b[0m in \u001b[0;36mkfold\u001b[0;34m(data1, data2, data3, data4, data5, hidden_layer, activation)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m#fold 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mtraining4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0maccuracy4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;31m#print(\"accuracy:\", accuracy4, \"loss\", loss4, \"iteration\", iteration4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m#end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-493201ce5ede>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training, testing, hidden_layer, learning_rate, activation)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m#create features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtesting_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-493201ce5ede>\u001b[0m in \u001b[0;36mcreate_features\u001b[0;34m(raw_data, fs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mrpeaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_r_peaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpeaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mrri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-493201ce5ede>\u001b[0m in \u001b[0;36mcal_r_peaks\u001b[0;34m(signal, sampling_rate)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     rpeaks, = ecg.hamilton_segmenter(signal=signal,\n\u001b[0;32m---> 48\u001b[0;31m                                      sampling_rate=sampling_rate)\n\u001b[0m\u001b[1;32m     49\u001b[0m     rpeaks, = ecg.correct_rpeaks(signal=signal,\n\u001b[1;32m     50\u001b[0m                                  \u001b[0mrpeaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrpeaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/biosppy/signals/ecg.py\u001b[0m in \u001b[0;36mhamilton_segmenter\u001b[0;34m(signal, sampling_rate)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;31m# meanval = np.mean(window)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mw_peaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_extrema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m         \u001b[0mw_negpeaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_extrema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0mzerdiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0mw_peaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_peaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzerdiffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_loss2, best_hidden2 = modelSelection(list_activation, A3, data1, data2, data3, data4, data5)\n",
    "print(\"g_loss2: \", g_loss2, \" best_hiddent2: \", best_hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
